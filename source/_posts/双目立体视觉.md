---
title: 双目立体视觉介绍
date: 2015-08-11 00:00:00
categories: 技术博文
tags: [CV, 标定]
---

> **导言：** 上一篇博客讲述了单目标定的原理，并展示了使用OpenCV提供的标定函数对棋盘格和圆点盘进行标定结果。这篇博客记录最近学习双目立体视觉的一些收获。如果对单目标定的原理有所掌握，双目视觉中对级几何、双目标定等知识理解起来应该很简单，图像校正仔细思考一下也不难。**最难的还是在于立体匹配生成视差图的部分**。这里的难，不是说理解这个步骤要实现什么效果难，而是如何实现好的效果，难！立体视觉的研究主要也集中在匹配上，新的方法和数据库还是在不断地被提出。这篇博客还是将重点放在了整个双目视觉处理的整个流程上，对于立体匹配这部分只介绍一些基本的方法。但通过这些基本介绍，我相信读者可以理解新的方法相比传统方法的改进。

<!-- more -->
 
##三角测量
三角测量是双目测距的基础，它从原理上解释了为什么左、右图像上对应点之间的关系，可以转换为点的深度信息。

假设我们两台相机固定在支架上，两台相机的光轴平行，并且像平面精确地位于一个平面上，焦距一致，主点也已校准。两个相机之间的关系可以用下图来表示。

<img src="https://farm1.staticflickr.com/566/19832797853_3fe630ac4e_z.jpg" alt="三角测量" />

<p dir="ltr" align="middle" style="font-size:xx-small"> 三角测量示意图</p>

$$
\frac{Z}{T} = \frac{Z-f}{T-x^l+x^r}\Rightarrow Z=\frac{fT}{x^l-x^r}
$$

$x^l-x^r$就叫做**视差**，两相机光轴之间的距离$T$叫做**基线距离**。可以看到：

 1. 固定基线距离和焦距下，视差越大，距离越小。这一点很好理解：近大远小，深度距离$Z$大，点在图像中的视差就小。
 2. 当视差很小时，微小的变化都会导致深度值的巨大变化，因此噪声的影响会非常大。也就是说：立体相机只能在物体离相机比较近的时候测距才比较准。(现在有些双目相机在20米开外仍然可以使用，这就需要在匹配过程中非常准确排除掉噪声，将每一点的视差都稳定地处在一个大致正确的范围内)。
 3.   上面一条的数学描述为：给定允许的最小视差增量$\Delta d$，最小深度范围精度为：$\Delta{Z}=\frac{Z^2}{fT}\Delta{d}$ 
 4. 当双目系统最大视差和最小视差分别为$d_{max}$和$d_{min}$时，双目的深度可测量范围为：$\frac{fT}{d_max}$ 到 $\frac{fT}{d_{min}$。

 ## 对极几何和基本矩阵
 
上面说过：三角测量是双目测距的基础。对级几何和基本矩阵则是**快速计算出视差**最重要的理论基础。如果没有对级几何的约束，一个图像(设n*n的正方形图像)上某一点，在相同大小的另一幅图像找对应点产生视差，将是O(n^2)的算法。有了对级几何约束，很简单的处理(后面将看到是**图像校正**)就可以将算法复杂度简化为O(n)。

一个摄像机光轴中心投影在另一个像平面的位置，叫做$极点$。以《学习OpenCV》那本书中的插图为例：

<img src="https://farm1.staticflickr.com/280/19835160193_bb3ac02718_z.jpg" alt="对级几何" />

<p dir="ltr" align="middle" style="font-size:xx-small">对极几何约束</p>

左边相机光轴$O_l$投影到右边平面的点为$e_r$，对应的，右边相机光轴$O_r$投影到左边平面的点为$e_l$。任意点$P$与$O_l O_r$线段组成的平面与两个投影面相交分别形成的两条直线，叫做**极线**。

极线最重要的性质是：

>给定一幅图像上的一个特征，它在另一幅图像上的匹配师徒一定在对应的极线上。这就是"对极约束"。

其余的性质有：

基本矩阵为自由度为7的奇异矩阵。

对极几何的代数表示便是基础矩阵，它限定了空间上某一点$P$在两个摄像机像平面上的投影坐标$q_l$和$q_r$之间的关系：

$$
q_r^TFq_l=0
$$

矩阵$F$就是基本矩阵。

左右相机的对极线为：

 - ${I}'=Fx$是对应于$x_l$的对极线
 - $I=F^Tx$是对应于$x_r$的对极线

左相机和右相机的极点分别满足：
$$
Fe_l=0，F^Te_r=0
$$
 
 基本矩阵可以通过两幅图像的对应点直接得到，甚至不用预先知道相机的内参。求解基本矩阵有不同的方法，OpenCV提供了四种，分别是7点算法、8点算法、RANSAC算法和LMeds算法。《***Multiview Geometry in Computer Vision***》的整个第11章都在讲F矩阵的不同求法。

##双目测量的流程

文章开始介绍的三角测量做了太多的假设：光轴平行，像平面严格处于一个平面，图像无畸变，焦距一致。但实际上是很难制造出如此完美的相机系统的。幸运的是，在两个相机关系相对比较良好（不需要有假设的那么苛刻），理想的条件是可以通过数学方法来达到的。

因此双目视觉的流程可以总结为：

 1. 相机各自标定和矫正畸变
 2. 左右图像矫正，使光轴平行并且行对齐
 3. 立体匹配，在对极约束下寻找对应点
 4. 利用三角测量重投影产生深度图

第一步在[单目标定一文](http://pangbo.co/%E6%8A%80%E6%9C%AF%E5%8D%9A%E6%96%87/2015/08/06/%E5%8D%95%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A/)中已经讲过了，第四步三角测量在刚才一节中也讲过。现在重点来讲述图像校正和立体匹配的内容，在讲述这些内容之前，先将一下立体标定。

##立体标定

立体标定的目标是求解两个相机之间的RT矩阵。假设点P=(X,Y,Z)在左边摄像机坐标系下的坐标$P_l=R_lP+T_l$，在右边摄像机下的坐标$P_r=R_rP+T_r$。需要计算的是$P_l$到$P_r$的转换$P_r=RP_l+T$,则可以推出：

$$
R=R_rR_l^T
$$

$$
T=T_r-R_l^TT_l
$$

因此分别使用单目相机的标定过程计算出两组外参，带入公式中，即可计算出两个相机的相对朝向RT。由于噪声和舍入误差，每组结果计算出的RT可能有所不同，因此可以使用RT的中值作为正式结果的初始近似值，然后运行Levenberg-Marquardt迭代算法找到鲁棒的值。

##立体校正

两台摄像机像平面共面并且行对准的情况基本不存在，因此高效的方法是预先将图像校正为行对准的，然后在对应行找匹配点。

OpenCV介绍了两种校正方法，一种是不需要立体校正的Hartley算法，另一种Bouguet算法则需要知道两个相机的RT关系。

###Hartley算法
大概思想为：
1，先计算出基础矩阵和两个极点$e_l$和$e_r$
2，计算将$e_r$旋转到$(f,0,1)$的旋转矩阵$R$和将右图像上感兴趣点（比如图像中心）到原点的平移$T$
3,   将$(f,0,1)^T$通过矩阵

$$
G=\begin{bmatrix}
1 & 0 & 0\\ 
0 & 1 & 0 \\ 
-1/f & 0 & 1
\end{bmatrix}
$$

映射到$(f,0,0)^T$无穷远处，即光轴平行。映射$H_r=GRT$

4，搜寻与$H_r$匹配的单应矩阵$H_l$,将左极点发送到无穷远处，并保证行对准。能用到的准则是：让校准之后的两幅图像匹配点之间的间距最小。也就是查找到$H_l$，使左右匹配点的总视差最小：

$$
\sum_i{d(H_lP_i^l,H_lP_i^l)^2}
$$

具体求解可参考《***Multiview Geometry in Computer Vision***》305页的内容。

##立体匹配

之前的步骤：矫正畸变、图像行对准都是可以使用标定板预先计算好相关参数，然后在处理图像时直接使用的，但立体匹配这个步骤所面对的，则是真实的、可能有各种极端情况的图片。准确来说，完成之前的步骤，图像匹配这个步骤和双目视觉关系已经不大了，完全是使用图像处理的技术，考虑种种可能性，选择好的匹配对应点的过程。

匹配的过程，会面对的问题有：图像畸变和噪声、表面光斑，透视投影变换、视角畸变，无纹理区域，重复模式、遮挡、不连续等问题。

有人统计21世纪起计算机视觉影响力最大的20篇期刊论文([链接](http://www.cnblogs.com/youth0826/archive/2012/12/04/2801481.html)),排名第14位的论文"*A taxonomy and evaluation of dense two-frame stereo correspondence algorithms*"就是关于双目立体成像的。其提供了一个数据库和评估方法，测试双目立体成像的效果，并且可以在线提交自己的算法。论文还对匹配问题进行了分类，按照论文的理解，立体匹配过程分为如下几个步骤：

 1. 匹配代价计算
 2. 匹配代价汇总
 3. 视差生成/优化
 4. 视差细化

算法按视差优化生成可以分为：

**局部算法**一般包括1,2,3三个步骤，第三个步骤为简单的赢者通吃(Winner Takes All 或WTA)策略。OpenCV提供的块匹配算法(BM)就是局部匹配算法。

**全局算法**包括1,3两个步骤，第三个步骤会考虑全局或者半全局的约束。OpenCV提供的SGBM是半全局优化的方法。

其中计算点对之间距离时，又可分为：

绝对值距离（SAD）

$$
e(x,y,d)=\sum_{x \subseteq S }\left | I_R(x,y)-I_T(x+d,y) \right |
$$

平方距离（SSD）

$$
e(x,y,d)=\sum_{x \subseteq S } (I_R(x,y)-I_T(x+d,y))^2
$$

或者考虑排除干扰点的鲁棒匹配距离,比如TAD：

$$
e(x,y,d)= \sum_{x \subseteq S }min\{|I_R(x,y)-I_T(x+d,y|,T\}
 $$

了解到这个，块匹配实际上就是使用固定大小的block，使用某种距离（OpenCV中为SAD）进行匹配，然后采用策略比如WTA得到视差图。

固定窗口块匹配是实际使用的最广的匹配算法。其简单快速地实现，对内存要求少，可以在FPGA等硬件上实现。
 







